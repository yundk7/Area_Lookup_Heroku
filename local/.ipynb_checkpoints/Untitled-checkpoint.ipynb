{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from app import zillowELT,dfs_shape_merge,google_zip_df,merge_dfs,regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typ = request.form[\"typ\"]\n",
    "# srch = request.form[\"srch\"]\n",
    "# poi = request.form[\"pois\"]\n",
    "typ = \"city\"\n",
    "srch = \"chicago\"\n",
    "poi = \"starbucks,restaurant\"\n",
    "\n",
    "con_search = create_engine(\"sqlite:///search.sqlite\")\n",
    "df = pd.DataFrame({\"Title\":[\"Type\",\"Search\",\"Place of Interests\"],\"Input\":[typ,srch,poi]})\n",
    "df.to_sql(\"search\", con_search, if_exists=\"replace\", index=False)\n",
    "\n",
    "typ = typ.lower()\n",
    "#to take account typing differences such as space and capital letters\n",
    "srch = srch.upper().replace(\" \",\"\").split(\",\")\n",
    "poi = poi.upper()\n",
    "\n",
    "#call in information to find what zipcodes are in search area(eg:chicago)\n",
    "con_us = create_engine(\"sqlite:///us_db.sqlite\")\n",
    "city = pd.read_sql(\"city\",con_us)\n",
    "city = city[city[typ].astype(str).str.replace(\" \",\"\").str.upper().isin(srch)]\n",
    "#from zip codes obtained, select information needed from each database\n",
    "zips = list(city[\"zip\"])\n",
    "\n",
    "#         rent = pd.read_csv(\"https://raw.githubusercontent.com/yundk7/area_lookup_heroku/master/local/Zip_ZriPerSqft_AllHomes.csv\")\n",
    "rent = pd.read_sql(\"zillow_rent\",con_us)\n",
    "rent = zillowELT(rent,zips)\n",
    "# rent_plt = zillowplot(rent.T)\n",
    "\n",
    "#         sales = pd.read_csv(\"https://raw.githubusercontent.com/yundk7/area_lookup_heroku/master/local/Zip_MedianListingPricePerSqft_AllHomes.csv\")\n",
    "sales = pd.read_sql(\"zillow_sales\",con_us)\n",
    "sales = zillowELT(sales,zips)\n",
    "# sales_plt = zillowplot(sales.T)\n",
    "\n",
    "dfs = dfs_shape_merge(rent,sales)\n",
    "rent1 = dfs[0]\n",
    "sales1 = dfs[1]\n",
    "ratio = (rent1 * 12) / sales1 * 100\n",
    "# ratio_plt = zillowplot(ratio.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting recent 5 for regression later\n",
    "n = -5\n",
    "rent = rent.iloc[:,n:]\n",
    "rent = pd.DataFrame({\"rent\":rent.mean(axis=1)})\n",
    "\n",
    "sales = sales.iloc[:,n:]\n",
    "sales = pd.DataFrame({\"sales\":sales.mean(axis=1)})\n",
    "\n",
    "ratio = ratio.iloc[:,n:]\n",
    "ratio = pd.DataFrame({\"roi\":ratio.mean(axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the zips are outer merge of zips in rent and sales\n",
    "zip_rent = pd.DataFrame(rent.index.values)\n",
    "zip_sales = pd.DataFrame(sales.index.values)\n",
    "zips = list(pd.merge(zip_rent,zip_sales,on=0,how=\"outer\")[0])\n",
    "\n",
    "#preparing dataframe for regression with zipcode data, also to be used in google api search\n",
    "area = pd.read_sql(\"area\",con_us)\n",
    "area = area[area[\"zip\"].isin(zips)]\n",
    "crime = pd.read_sql(\"crime\",con_us)\n",
    "\n",
    "regr = pd.merge(area,crime,on=\"zip\")\n",
    "regr.set_index(\"zip\",inplace=True)\n",
    "\n",
    "#since heroku is limited with request time, sampling out 8 zip codes to analyze\n",
    "# sample = 8\n",
    "# if len(df) < sample:\n",
    "#     sample = len(df)\n",
    "# df = df.sample(sample)\n",
    "\n",
    "#using regression dataframe for reference\n",
    "api = google_zip_df(regr,poi)\n",
    "# geo_plt = plotly_geo(api)\n",
    "# plotly_geo(api)\n",
    "con_sum = create_engine(\"sqlite:///summary.sqlite\")\n",
    "api.to_sql(\"api\",con_sum,if_exists=\"replace\",index=False)\n",
    "\n",
    "#preparing api results for regression\n",
    "API_df = api[api[\"poi\"]!=\"YOU ARE HERE\"]\n",
    "API_df[[\"reviews\"]]=API_df[[\"reviews\"]].apply(pd.to_numeric, errors='coerce')\n",
    "count_df = API_df.pivot_table(fill_value=0,index = \"zip\",columns = [\"poi\"], values=\"reviews\",aggfunc=[\"count\"])[\"count\"].reset_index()\n",
    "mean_df = API_df.pivot_table(fill_value=0,index = \"zip\",columns = [\"poi\"], values=\"reviews\",aggfunc=[\"mean\"])[\"mean\"].reset_index()\n",
    "API_pivot = pd.merge(count_df,mean_df,on=\"zip\",suffixes=[\"_count\",\"_mean\"])\n",
    "API_pivot.set_index(\"zip\",inplace=True)\n",
    "\n",
    "regr = merge_dfs([regr,API_pivot])\n",
    "\n",
    "regr.drop(columns = [\"coordinates\",\"area\",\"radius\"],inplace=True)\n",
    "\n",
    "#regression on each\n",
    "rent = merge_dfs([rent,regr])\n",
    "rent = regression(rent)\n",
    "rent[0].to_sql(\"rent0\",con_sum,if_exists=\"replace\",index=False)\n",
    "rent[1].to_sql(\"rent1\",con_sum,if_exists=\"replace\",index=True)\n",
    "\n",
    "sales = merge_dfs([sales,regr])\n",
    "sales = regression(sales)\n",
    "sales[0].to_sql(\"sales0\",con_sum,if_exists=\"replace\",index=False)\n",
    "sales[1].to_sql(\"sales1\",con_sum,if_exists=\"replace\",index=True)\n",
    "\n",
    "ratio = merge_dfs([ratio,regr])\n",
    "ratio = regression(ratio)\n",
    "ratio[0].to_sql(\"ratio0\",con_sum,if_exists=\"replace\",index=False)\n",
    "ratio[1].to_sql(\"ratio1\",con_sum,if_exists=\"replace\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
